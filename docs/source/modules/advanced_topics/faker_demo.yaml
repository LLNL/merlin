   # TODO: add venv building to the spec? -> can this be dependency
   #       add file system cleanup after each iteration
   #       parallelize the iteration accumulation in cumulative_sample_proc

   description:
     name: dynamic_sampling_demo
     description: Demo dynamic sampling workflow

   env:
     variables:
       OUTPUT_PATH: ./name_studies
       ITER_OUTPUT: $(SPECROOT)/$(OUTPUT_PATH)/iter_outputs # Iteration and cumulative results
       COLLECT: $(SPECROOT)/sample_collector.py
       POST_PROC: $(SPECROOT)/sample_processor.py # Process single iterations' results
       CUM_POST_PROC: $(SPECROOT)/cumulative_sample_processor.py # Process all iterations
       POST_NPROCS: 36          # Number of threads for post proc scripts
       PYTHON: /usr/WS2/white242/merlin_dev_2/venv_merlin_py3_7/bin/python
       ITER: 1
       MAX_ITER: 10

   batch:
      type: flux
      bank: testbank
      queue: pdebug
      shell: /bin/bash
      nodes: 1

   ########################################
   # Study definition
   ########################################
   study:
      - name: sample_names
        description: Record samples from the random name generator
        run:
           cmd: |
             $(LAUNCHER) echo "$(NAME)"
             $(LAUNCHER) echo "$(NAME)" > name_sample.out
           nodes: 1
           procs: 1
           task_queue: name_queue
  
      - name: collect
        description: Collect all samples generated 
        run:
           cmd: |
             echo $(MERLIN_GLOB_PATH)
             echo $(sample_names.workspace)

             ls $(sample_names.workspace)/$(MERLIN_GLOB_PATH)/name_sample.out | xargs $(PYTHON) $(COLLECT) -out collected_samples.txt --np $(POST_NPROCS)
             
           nodes: 1
           procs: 1
           depends: [sample_names_*]
           task_queue: post_proc_queue

      - name: post-process
        description: Post-Process collection of samples, counting occurences of unique names
        run:
           cmd: |
             $(PYTHON) $(POST_PROC) $(collect.workspace)/collected_samples.txt --results $(ITER_OUTPUT)/iter_$(ITER)_results.json
             
           nodes: 1
           procs: 1
           depends: [collect]
           task_queue: post_proc_queue

      - name: run-more-samples
        description: Generate new set of samples and rerun, or generate some descriptive plots/statistics
        run:
          cmd: |
            if [ $(ITER) -ge $(MAX_ITER) ] ; then
               echo "done"
               $(PYTHON) $(CUM_POST_PROC) $(ITER_OUTPUT)/iter_*_results.json --np $(POST_NPROCS) --hardcopy $(ITER_OUTPUT)/cumulative_results.png
            else
               next_iter=$(ITER)
               ((next_iter=next_iter+1))
               echo "Starting iteration " $next_iter
               cd $(SPECROOT)
               merlin run $(SPECROOT)/faker_demo.yaml --vars ITER=$next_iter
            fi
          nodes: 1
          procs: 1
          depends: [post-process]
          task_queue: post_proc_queue
      
           
   ########################################
   # Worker and sample configuration
   ########################################  
   merlin:
  
     resources:
       task_server: celery
  
       overlap: False
  
       # Customize workers  NOTE: abuse this for scaling study: prefetch mult increase
       #   - celery->rabbit query overhead for fast jobs
       workers:
           nameworkers:
               args: --concurrency 36 --prefetch-multiplier 3
               steps: [sample_names]      
               nodes: 1
               machines: [borax, quartz]      

          # NOTE: specifying wrong step leaves orphaned queue -> purge first!
          # also, invalid host name appears to fail silently
           postworkers:
               args: --concurrency 1 --prefetch-multiplier 1
               steps: [post-process]
               nodes: 1 
               machines: [borax, quartz]
  
     ###################################################
     samples:
       column_labels: [NAME]
       file: $(MERLIN_INFO)/samples.csv
       generate:
         cmd: |
           $(PYTHON) $(SPECROOT)/faker_sample.py -n 200 -outfile=$(MERLIN_INFO)/samples.csv